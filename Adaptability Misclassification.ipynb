{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xdf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import resampy\n",
    "import mne\n",
    "import xdf_interface as xif\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.models.deep4 import Deep4Net\n",
    "\n",
    "model = Deep4Net(64, 2, 600, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "optimizer = AdamW(model.parameters(), lr=.8*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "#optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1, cropped = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "#folder of the initial model\n",
    "modelfolder = ''\n",
    "#folder of the adapted models\n",
    "gradfolder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load(path+modelpath+'deep_4_params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.models.util import to_dense_prediction_model\n",
    "to_dense_prediction_model(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_framerate = 250;\n",
    "timeframe_start = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.array(['data_1.xdf', 'data_2.xdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = xif.bdonline_extract(path, files, timeframe_start,target_framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Supercrops from Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trials2supercrops(X,y):    \n",
    "    data = np.empty([64, 600, 0])\n",
    "    classes = np.array([])\n",
    "    \n",
    "    for i in np.arange(len(X)):\n",
    "        print(\"Reading trial \", i+1, \" of \", len(X))\n",
    "    \n",
    "        end = 600\n",
    "        while end < X[i].shape[1]:\n",
    "            data = np.append(data, X[i][:, (end-600):end,None ],2)\n",
    "            classes = np.append(classes, y[i])\n",
    "            end = end + 125\n",
    "        end = X[i].shape[1]\n",
    "        data = np.append(data, X[i][:, (end-600):end,None ],2)\n",
    "        classes = np.append(classes, y[i])\n",
    "    return(data,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty([64, 600, 0])\n",
    "classes = np.array([])\n",
    "\n",
    "d,c = trials2supercrops(X,y)\n",
    "data = np.append(data, d, 2)\n",
    "classes = np.append(classes, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Missclassification for each Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(model, data, classes):\n",
    "    correct = 0\n",
    "    for i in np.arange(data.shape[2]):\n",
    "        in_np = data[:,:,i].T\n",
    "        in_var = np_to_var(in_np.T[None,:,:,None], dtype=np.float32)\n",
    "        in_var = in_var.cuda()\n",
    "        pred = var_to_np(model(in_var))\n",
    "        pred = np.exp(pred)\n",
    "        if pred.ndim > 2:\n",
    "            pred = np.mean(pred, axis=2).squeeze()\n",
    "            \n",
    "        if np.argmax(pred) == classes[i]:\n",
    "            correct += 1\n",
    "            \n",
    "        \n",
    "    misclass = 1-(float(correct)/len(classes))\n",
    "    return misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.empty(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(X)):\n",
    "    print(\"Evaluating Trial \",i+1,\" of \", len(X))\n",
    "    \n",
    "    if i < 10:\n",
    "        net = path+modelfolder+'deep_4_params'\n",
    "    else:\n",
    "        net = path+gradfolder+'state_dict_Trial-'+str(i)+'_Epoch-4'\n",
    "        \n",
    "    model.load_state_dict(torch.load(net))\n",
    "    model.eval()\n",
    "    accs[i] = test_network(model, data, classes)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(accs[:],'+-', lw = 2.5,color = plt.cm.bone(c/(len(nnets)+2)))\n",
    "\n",
    "\n",
    "plt.xlim(0, len(X))\n",
    "\n",
    "plt.vlines(10,0,1, lw=.8)\n",
    "plt.hlines(.5,0,len(X),alpha=.4, linestyles = 'dashed')\n",
    "\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.text(11, .8, 'start training', size = 16)\n",
    "\n",
    "#plt.suptitle(\"TITLE\", size = 20)\n",
    "plt.ylabel('Misclassification', size = 24)\n",
    "plt.xlabel('Trial', size = 24)\n",
    "plt.gca().tick_params(labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
